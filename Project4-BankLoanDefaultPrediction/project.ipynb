{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Loan Defaulter Hackathon Project\n",
    "### Submitted by Himanshu Saini\n",
    "#### Dataset Link: https://www.kaggle.com/datasets/ankitkalauni/bank-loan-defaulter-prediction-hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "df_train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"First 5 rows:\\n\", df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataset\n",
    "print (\"Dataset shape:\", df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column types and null counts\n",
    "print (\"Column types and null counts:\\n\", df_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null counts\n",
    "print (\"Null counts:\\n\", df_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types counts grouopby columns\n",
    "for dtype, cols in df_train.groupby(df_train.dtypes, axis=1):\n",
    "    print(f\"{dtype} ({len(cols.columns)} columns):\")\n",
    "    print(list(cols.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print (\"Summary statistics:\\n\", df_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train dataset basic information\n",
    "#### 1. There are 35 columns.\n",
    "#### 2. 67463 entries.\n",
    "#### 3. Null counts zero.\n",
    "#### 4. Datatype distribution:\n",
    "```\n",
    "int64 (17 columns):\n",
    "['ID', 'Loan Amount', 'Funded Amount', 'Term', 'Delinquency - two years', 'Inquires - six months', 'Open Account', 'Public Record', 'Revolving Balance', 'Total Accounts', 'Collection 12 months Medical', 'Last week Pay', 'Accounts Delinquent', 'Total Collection Amount', 'Total Current Balance', 'Total Revolving Credit Limit', 'Loan Status']\n",
    "\n",
    "float64 (9 columns):\n",
    "['Funded Amount Investor', 'Interest Rate', 'Home Ownership', 'Debit to Income', 'Revolving Utilities', 'Total Received Interest', 'Total Received Late Fee', 'Recoveries', 'Collection Recovery Fee']\n",
    "\n",
    "object (9 columns):\n",
    "['Batch Enrolled', 'Grade', 'Sub Grade', 'Employment Duration', 'Verification Status', 'Payment Plan', 'Loan Title', 'Initial List Status', 'Application Type']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify train dataset column types.\n",
    "df_train_categorical_cols = df_train.select_dtypes(include=\"object\").columns.tolist()\n",
    "df_train_numerical_cols = df_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unique counts for train dataset columns.\n",
    "for col in df_train_numerical_cols:\n",
    "    if df_train[col].nunique()<=200:\n",
    "        print (col, df_train[col].nunique())\n",
    "\n",
    "for col in df_train_categorical_cols:\n",
    "    if df_train[col].nunique()<=200:\n",
    "        print (col, df_train[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.nunique().sort_values().plot(kind=\"barh\", figsize=(10, 12))\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\"Unique Values per Column\")\n",
    "plt.axvline(x=40, color='red', linestyle='--', label='Threshold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the categorical features out from train data.\n",
    "df_train_filter = df_train.loc[:, df_train.nunique() <= 40]\n",
    "df_train_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for col in df_train_numerical_cols:\n",
    "    sns.boxplot(data=df_train, x=\"Loan Status\", y=col)\n",
    "    plt.title(f\"{col} vs Loan Status\")\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define outlier capping function (calling and flooring).\n",
    "def outlier_processing(x):\n",
    "     x = x.clip(lower=x.quantile(0.05), upper=x.quantile(0.95))\n",
    "     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Capping to Numeric Columns of train dataset.\n",
    "#df_train[df_train_numerical_cols] = df_train[df_train_numerical_cols].apply(lambda x : outlier_processing(x))\n",
    "df_train[df_train_numerical_cols] = df_train[df_train_numerical_cols].apply(outlier_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe Data After Capping\n",
    "df_train[df_train_numerical_cols].describe(percentiles=[0.01,0.05,0.25,0.50,0.75,0.95,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance of Columns\n",
    "df_train[df_test_numerical_cols].var().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds\n",
    "drop_threshold = 0.0001\n",
    "flag_threshold = 0.05\n",
    "\n",
    "# Drop zero/near-zero variance columns\n",
    "zero_var_cols = df_train[df_train_numerical_cols].var(numeric_only=True)\n",
    "zero_var_cols = zero_var_cols[zero_var_cols < drop_threshold].index.tolist()\n",
    "\n",
    "# Flag low-variance columns for review (but not yet dropped)\n",
    "low_var_cols = df_train[df_train_numerical_cols].var(numeric_only=True)\n",
    "low_var_cols = low_var_cols[(low_var_cols >= drop_threshold) & (low_var_cols < flag_threshold)].index.tolist()\n",
    "\n",
    "print(\"Drop these (zero or near-zero variance):\", zero_var_cols)\n",
    "print(\"Review these (low variance):\", low_var_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize result dictionary\n",
    "cat_analysis = {}\n",
    "\n",
    "# Thresholds\n",
    "dominance_threshold = 0.95\n",
    "high_card_threshold = 100\n",
    "\n",
    "# Analyze each categorical column\n",
    "for col in df_train_categorical_cols:\n",
    "    n_unique = df_train[col].nunique(dropna=False)\n",
    "    top_freq = df_train[col].value_counts(normalize=True, dropna=False).iloc[0]\n",
    "    cat_analysis[col] = {\n",
    "        \"Unique Values\": n_unique,\n",
    "        \"Top Category %\": round(top_freq * 100, 2),\n",
    "        \"Drop (High Cardinality)\": n_unique > high_card_threshold,\n",
    "        \"Drop (Dominant Category)\": top_freq > dominance_threshold\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame\n",
    "cat_analysis_df = pd.DataFrame(cat_analysis).T.sort_values(by=\"Unique Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above analysis we found the following:\n",
    "### 1. Drop numerical col \"Collection 12 months Medical\", \"Accounts Delinquent\" because they have zero variance therefore, should drop.\n",
    "### 2. Drop categorical col \"Payment Plan\", \"Application Type\" because constant values and highly imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['ID', 'Collection 12 months Medical', 'Accounts Delinquent', 'Payment Plan', 'Application Type']\n",
    "df_train.drop(columns=drop_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will analyze the categorical columns and suggest encoding methods based on their characteristics.\n",
    "# Select categorical columns\n",
    "cat_cols = df_train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Prepare summary\n",
    "encoding_suggestions = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    unique_vals = df_train[col].nunique(dropna=False)\n",
    "    top_cat_pct = df_train[col].value_counts(normalize=True, dropna=False).iloc[0] # The percentage of rows that belong to the most frequent category in a given column.\n",
    "\n",
    "    if unique_vals <= 10:\n",
    "        if col in ['Grade']:  # Known ordinal from domain\n",
    "            encoding_type = \"Ordinal Encoding\"\n",
    "        else:\n",
    "            encoding_type = \"One-Hot Encoding\"\n",
    "    elif 10 < unique_vals <= 50:\n",
    "        encoding_type = \"Label Encoding\"\n",
    "    elif unique_vals > 50:\n",
    "        encoding_type = \"Frequency Encoding / Target Encoding\"\n",
    "    else:\n",
    "        encoding_type = \"Review Manually\"\n",
    "\n",
    "    dominance_flag = \"Dominant Category\" if top_cat_pct > 0.95 else \"\"\n",
    "    \n",
    "    encoding_suggestions.append({\n",
    "        \"Column\": col,\n",
    "        \"Unique Values\": unique_vals,\n",
    "        \"Top Category %\": round(top_cat_pct * 100, 2),\n",
    "        \"Suggested Encoding\": encoding_type,\n",
    "        \"Note\": dominance_flag\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "encoding_df = pd.DataFrame(encoding_suggestions).sort_values(by=\"Unique Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemnting encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- 1. Ordinal Encoding for 'Grade'\n",
    "grade_order = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7}\n",
    "df_train[\"Grade\"] = df_train[\"Grade\"].map(grade_order)\n",
    "\n",
    "# --- 2. Label Encoding for 'Sub Grade' and 'Batch Enrolled'\n",
    "label_cols = [\"Sub Grade\", \"Batch Enrolled\"]\n",
    "le = LabelEncoder()\n",
    "for col in label_cols:\n",
    "    df_train[col] = le.fit_transform(df_train[col])\n",
    "\n",
    "# --- 3. Frequency Encoding for 'Loan Title'\n",
    "freq_map = df_train[\"Loan Title\"].value_counts().to_dict()\n",
    "df_train[\"Loan Title\"] = df_train[\"Loan Title\"].map(freq_map)\n",
    "\n",
    "# --- 4. One-Hot Encoding for 'Initial List Status', 'Employment Duration', 'Verification Status'\n",
    "one_hot_cols = [\"Initial List Status\", \"Employment Duration\", \"Verification Status\"]\n",
    "df_train_encoded = pd.get_dummies(df_train, columns=one_hot_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Loan Status\" in df_train_encoded.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Imports ---\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Split the train and test datasets ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train_encoded.drop(columns=[\"Loan Status\"])\n",
    "y = df_train_encoded[\"Loan Status\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Check the class distribution ---\n",
    "print(\"Original Class Distribution:\")\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Apply SMOTE ---\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(\"Distribution after SMOTE:\")  \n",
    "print(Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Apply NearMiss ---\n",
    "nearmiss = NearMiss(version=1)\n",
    "X_train_nm, y_train_nm = nearmiss.fit_resample(X_train, y_train)\n",
    "print(\"Distribution after NearMiss:\")\n",
    "print(Counter(y_train_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Compare in Table ---\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Original\": pd.Series(Counter(y_train)),\n",
    "    \"SMOTE\": pd.Series(Counter(y_train_smote)),\n",
    "    \"NearMiss\": pd.Series(Counter(y_train_nm))\n",
    "}).T\n",
    "comparison_df.columns = [\"Non-Defaulter (0)\", \"Defaulter (1)\"]\n",
    "print(\"Class Distribution Comparison:\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Plotting ---\n",
    "comparison_df.plot(kind=\"bar\", figsize=(8, 4), colormap=\"viridis\")\n",
    "plt.title(\"Class Distribution: Original vs SMOTE vs NearMiss\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Metrics (for classification)\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "# Model Selection (Optional for tuning)\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model, X_train, y_train, X_test, y_test, name=\"\", refit=True, positive_label=1):\n",
    "    # Fit only if requested\n",
    "    if refit:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    # Get probabilities with the correct column for the positive class (I made a mistake here before.)\n",
    "    y_prob = None\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = model.predict_proba(X_test)\n",
    "        # Find the column index for the desired positive_label\n",
    "        pos_idx = np.where(model.classes_ == positive_label)[0][0]\n",
    "        y_prob = proba[:, pos_idx]\n",
    "\n",
    "    # Use sklearn's predict (which applies its own threshold consistently)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "    con_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Feature importance / coefficients\n",
    "    feature_importance = None\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        feature_importance = model.feature_importances_\n",
    "    elif hasattr(model, \"coef_\"):\n",
    "        try:\n",
    "            feature_importance = np.abs(model.coef_[0])\n",
    "        except Exception:\n",
    "            feature_importance = None\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Confusion Matrix\": con_mat,\n",
    "        \"Feature Importance\": feature_importance,\n",
    "        \"y_pred\": y_pred,      # include these for debugging/plots\n",
    "        \"y_prob\": y_prob,\n",
    "        # For debugging\n",
    "        \"classes_\": getattr(model, \"classes_\", None),\n",
    "        \"positive_label\": positive_label,\n",
    "        \"positive predicted\": (y_pred == positive_label).sum()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Evaluate on original data\n",
    "result_lr_orig = evaluateModel(lr, X_train, y_train, X_test, y_test, name=\"LogReg - Original\")\n",
    "\n",
    "# Evaluate on SMOTE-balanced data\n",
    "result_lr_smote = evaluateModel(lr, X_train_smote, y_train_smote, X_test, y_test, name=\"LogReg - SMOTE\")\n",
    "\n",
    "# Evaluate on NearMiss-balanced data\n",
    "result_lr_nm = evaluateModel(lr, X_train_nm, y_train_nm, X_test, y_test, name=\"LogReg - NearMiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lr_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lr_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lr_nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Evaluation\n",
    "\n",
    "| Resampling Strategy | Accuracy | Precision | Recall | F1 Score | ROC AUC | Comments                                                                            | Best Use Case                                                                                                         |\n",
    "| ------------------- | -------- | --------- | ------ | -------- | ------- | ----------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Original**        | 0.5470   | 0.0984    | 0.4775 | 0.1632   | 0.5157  | Moderate recall with low precision; class imbalance still impacts performance, leading to many false positives and a low ROC AUC. | When you need a quick baseline and want moderate recall without complex preprocessing.                                |\n",
    "| **SMOTE**           | 0.5399   | 0.0984    | 0.4671 | 0.1581   | 0.5102  | Similar to original; oversampling improves class balance but doesn't significantly boost performance—model likely limited by feature separability. | Balanced datasets where you expect model behavior similar to original but want to avoid bias toward majority class.   |\n",
    "| **NearMiss**        | 0.3406   | 0.0948    | 0.7171 | 0.1674   | 0.5082  | Significantly increases recall (captures more positives) but at the cost of accuracy and precision; high false positive rate due to aggressive undersampling. | Situations where missing a positive case is more costly than false alarms (e.g., fraud detection, medical screening). |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model setup\n",
    "dt = DecisionTreeClassifier(\n",
    "                            random_state=42,\n",
    "                            class_weight='balanced',\n",
    "                            max_depth=8, # Adjust max_depth as needed (6-12 is a good range to start with, but you can tune it further if needed.\n",
    "                            min_samples_leaf=30,\n",
    "                            min_samples_split=50,\n",
    "                            max_features='sqrt',  # Use square root of features for splits\n",
    "                            )\n",
    "\n",
    "# Original\n",
    "result_dt_orig = evaluateModel(dt, X_train, y_train, X_test, y_test, name=\"DecisionTree - Original\")\n",
    "\n",
    "# SMOTE\n",
    "result_dt_smote = evaluateModel(dt, X_train_smote, y_train_smote, X_test, y_test, name=\"DecisionTree - SMOTE\")\n",
    "\n",
    "# NearMiss\n",
    "result_dt_nm = evaluateModel(dt, X_train_nm, y_train_nm, X_test, y_test, name=\"DecisionTree - NearMiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dt_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dt_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dt_nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier Model Evaluation\n",
    "\n",
    "| Resampling Strategy | Accuracy | Precision | Recall | F1 Score | ROC AUC | Comments                                                                                  | Best Use Case                                                             |\n",
    "| ------------------- | -------- | --------- | ------ | -------- | ------- | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |\n",
    "| **Original**        | 0.5312   | 0.0934    | 0.4671 | 0.1557   | 0.5073  | Low precision and ROC AUC; tree overfitting likely; predicts many positives incorrectly.  | Balanced baseline; quick reference before resampling.                     |\n",
    "| **SMOTE**           | 0.6662   | 0.0914    | 0.2917 | 0.1391   | 0.4883  | Better accuracy from balancing classes, but recall dropped sharply; still poor precision. | When higher accuracy is more important than catching all positives.       |\n",
    "| **NearMiss**        | 0.3623   | 0.0934    | 0.6771 | 0.1642   | 0.5026  | High recall but accuracy suffers; many false positives due to aggressive undersampling.   | When maximizing recall is the top priority (e.g., catching all defaults). |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with base settings\n",
    "rf = RandomForestClassifier(\n",
    "                            random_state=42,\n",
    "                            class_weight='balanced',\n",
    "                            n_estimators=300,  # Number of trees in the forest\n",
    "                            max_depth=8,      # Maximum depth of each tree\n",
    "                            min_samples_leaf=30,  # Minimum samples required to be at a leaf node\n",
    "                            min_samples_split=50,  # Minimum samples required to split an internal node\n",
    "                            max_features='sqrt'  # Use square root of features for splits\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "result_rf_orig = evaluateModel(rf, X_train, y_train, X_test, y_test, name=\"RandomForest - Original\")\n",
    "\n",
    "# SMOTE\n",
    "result_rf_smote = evaluateModel(rf, X_train_smote, y_train_smote, X_test, y_test, name=\"RandomForest - SMOTE\")\n",
    "\n",
    "# NearMiss\n",
    "result_rf_nm = evaluateModel(rf, X_train_nm, y_train_nm, X_test, y_test, name=\"RandomForest - NearMiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rf_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rf_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rf_nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier Model Evaluation\n",
    "\n",
    "| Resampling Strategy | Accuracy | Precision | Recall | F1 Score | ROC AUC | Comments                                                                                                                |\n",
    "| ------------------- | -------- | --------- | ------ | -------- | ------- | ----------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Original**        | 0.7927   | 0.1114    | 0.1779 | 0.1370   | 0.5376  | Good overall accuracy, but still weak recall for minority class — many positives missed despite balanced class weights. |\n",
    "| **SMOTE**           | 0.7972   | 0.0926    | 0.1354 | 0.1100   | 0.4941  | Accuracy stays high, but SMOTE doesn’t improve recall here; possible overfitting to synthetic patterns.                 |\n",
    "| **NearMiss**        | 0.3035   | 0.0932    | 0.7484 | 0.1658   | 0.5053  | Very high recall (good at finding positives) but massive accuracy drop due to many false positives.                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with probability enabled for ROC AUC\n",
    "svc = SVC(\n",
    "            random_state=42,\n",
    "            probability=True,\n",
    "            class_weight='balanced',  # Use balanced class weights\n",
    "            kernel='rbf',  # Radial basis function kernel\n",
    "            C=1.0,  # Regularization parameter\n",
    "            gamma='scale'  # Kernel coefficient (1 / (n_features * X.var())) if 'scale' else 'auto'  # Use 'scale' for automatic scaling based on data\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "result_svc_orig = evaluateModel(svc, X_train, y_train, X_test, y_test, name=\"SVC - Original\")\n",
    "\n",
    "# SMOTE\n",
    "result_svc_smote = evaluateModel(svc, X_train_smote, y_train_smote, X_test, y_test, name=\"SVC - SMOTE\")\n",
    "\n",
    "# NearMiss\n",
    "result_svc_nm = evaluateModel(svc, X_train_nm, y_train_nm, X_test, y_test, name=\"SVC - NearMiss (Kaggle)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_svc_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_svc_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_svc_nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier Model Evaluation\n",
    "\n",
    "| Resampling Strategy | Accuracy | Precision | Recall | F1 Score | ROC AUC | Comments                                                                                                                                      | Best Use Case                                                                                                                  |\n",
    "| ------------------- | -------- | --------- | ------ | -------- | ------- | --------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **Original**        | 0.5966   | 0.0993    | 0.4167 | 0.1604   | 0.5185  | Balanced performance with slightly higher recall than precision; accuracy better than Logistic Regression & Decision Tree in Original setting | Works well for smaller to medium datasets with clear margins between classes; can capture non-linear relationships via kernels |\n",
    "| **SMOTE**           | 0.4736   | 0.0953    | 0.5521 | 0.1625   | 0.5129  | Significant drop in accuracy; recall improves but precision stays low, indicating many false positives                                        | Suitable for imbalanced datasets when the minority class needs better recall, though accuracy may drop                         |\n",
    "| **NearMiss**        | 0.3420   | 0.0920    | 0.6891 | 0.1623   | 0.4977  | Recall is highest among SVC runs, but accuracy is very low; model overpredicts positives                                                      | Can be used when recall is the main priority at the expense of accuracy, especially in cost-sensitive scenarios                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.divide(np.sum(y_train == 0), np.sum(y_train == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost\n",
    "xgb = XGBClassifier(\n",
    "                    random_state = 42,\n",
    "                    n_estimators=300,               # Number of boosting rounds\n",
    "                    learning_rate=0.05,             # Step size shrinkage\n",
    "                    max_depth=6,                    # Depth of each tree\n",
    "                    subsample=0.8,                  # Sample ratio for each tree\n",
    "                    colsample_bytree=0.8,           # Features ratio per tree\n",
    "                    reg_alpha=0.1,                  # L1 regularization\n",
    "                    reg_lambda=1,                   # L2 regularization\n",
    "                    scale_pos_weight=np.divide(np.sum(y_train == 0), np.sum(y_train == 1)),    # Adjust based on class imbalance\n",
    "                    use_label_encoder=False,        # Avoid warning for label encoder\n",
    "                    eval_metric=\"auc\",              # Track AUC during training\n",
    "                    tree_method='hist',             # Faster training\n",
    "                    gamma=1,                        # Minimum loss reduction required to make a further partition on a leaf node \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on Original Data\n",
    "result_xgb_orig = evaluateModel(xgb, X_train, y_train, X_test, y_test, name=\"XGBoost - Original\")\n",
    "\n",
    "# Evaluate on SMOTE-balanced Data\n",
    "result_xgb_smote = evaluateModel(xgb, X_train_smote, y_train_smote, X_test, y_test, name=\"XGBoost - SMOTE\")\n",
    "\n",
    "# Evaluate on NearMiss-balanced Data\n",
    "result_xgb_nm = evaluateModel(xgb, X_train_nm, y_train_nm, X_test, y_test, name=\"XGBoost - NearMiss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_xgb_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_xgb_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_xgb_nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model Evaluation\n",
    "\n",
    "| Model Variant                                | Accuracy | Precision | Recall | F1 Score | ROC AUC | Comment                                                                                                                                                                                | Best Use Case                                                                                                                    |\n",
    "| -------------------------------------------- | -------- | --------- | ------ | -------- | ------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| XGBoost – Original (with `scale_pos_weight`) | 0.7906   | 0.0916    | 0.1418 | 0.1113   | 0.5070  | Balanced class weight helped avoid predicting all negatives (unlike before), but recall is still low. Needs tuning of tree depth, learning rate, and regularization for better recall. | Suitable for structured/tabular data when explainability and feature importance are important, and imbalance handling is needed. |\n",
    "| XGBoost – SMOTE                              | 0.4439   | 0.0922    | 0.5665 | 0.1586   | 0.5012  | Recall improved significantly, but accuracy dropped sharply — typical with oversampling for imbalanced data. Still suffers from low precision, indicating many false positives.        | Useful when high recall is crucial (e.g., fraud detection, risk flagging) and you can tolerate false positives.                  |\n",
    "| XGBoost – NearMiss                           | 0.1507   | 0.0929    | 0.9335 | 0.1690   | 0.5064  | Extreme class balancing led to very high recall but almost unusable accuracy — predicts most cases as positive. Only viable if missing a positive is extremely costly.                 | Best when false negatives are unacceptable (e.g., safety-critical anomaly detection) and you can afford high false positives.    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class imbalance ratio.\n",
    "pos_weight = np.divide(np.sum(y_train == 0), np.sum(y_train == 1))\n",
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = \"roc_auc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost base model for tuning\n",
    "xgb = XGBClassifier(\n",
    "                    random_state = 42,\n",
    "                    tree_method='hist',\n",
    "                    eval_metric=\"auc\",\n",
    "                    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV parameters\n",
    "xgb_grid = {\n",
    "            \"max_depth\": [4, 6, 8],\n",
    "            \"learning_rate\": [0.03, 0.1],\n",
    "            \"n_estimators\": [300, 600],\n",
    "            \"subsample\": [0.8, 1.0],\n",
    "            \"colsample_bytree\": [0.8, 1.0],\n",
    "            \"min_child_weight\": [1, 3],\n",
    "            \"gamma\": [0, 1],\n",
    "            \"scale_pos_weight\": [pos_weight]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM base model for tuning\n",
    "lgbm = LGBMClassifier(\n",
    "                    random_state = 42,\n",
    "                    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV parameters\n",
    "lgbm_grid = {\n",
    "            \"max_depth\": [-1, 6, 8],\n",
    "            \"learning_rate\": [0.03, 0.1],\n",
    "            \"n_estimators\": [300, 600],\n",
    "            \"num_leaves\": [31, 63, 127],\n",
    "            \"subsample\": [0.8, 1.0],\n",
    "            \"colsample_bytree\": [0.8, 1.0],\n",
    "            \"reg_alpha\": [0.0, 0.1],\n",
    "            \"reg_lambda\": [0.0, 1.0],\n",
    "            \"scale_pos_weight\": [pos_weight]   # LightGBM supports this too\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost base model for tuning\n",
    "cat = CatBoostClassifier(\n",
    "                    random_state = 42,\n",
    "                    verbose=False,\n",
    "                    eval_metric=\"AUC\",\n",
    "                    loss_function='Logloss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV parameters\n",
    "cat_grid = {\n",
    "            \"depth\": [6, 8, 10],\n",
    "            \"learning_rate\": [0.03, 0.1],\n",
    "            \"iterations\": [300, 600],\n",
    "            \"l2_leaf_reg\": [1, 3, 5],\n",
    "            \"subsample\": [0.8, 1.0],\n",
    "            \"class_weights\": [[1.0, pos_weight]]  # [weight_for_class_0, weight_for_class_1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run GridSearchCV\n",
    "def run_grid(estimator, param_grid, name):\n",
    "    grid = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scoring,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        refit=True,     # refit best model on full training set\n",
    "        verbose=1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"\\n{name} — best AUC: {grid.best_score_:.4f}\")\n",
    "    print(\"Best params:\", grid.best_params_)\n",
    "    best_model = grid.best_estimator_\n",
    "    return name, best_model, grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for name, est, grid in [\n",
    "    (\"XGBoost (Grid)\", xgb, xgb_grid),\n",
    "    (\"LightGBM (Grid)\", lgbm, lgbm_grid),\n",
    "    (\"CatBoost (Grid)\", cat, cat_grid),\n",
    "]:\n",
    "    results.append(run_grid(est, grid, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best models on your held-out validation set\n",
    "rows = []\n",
    "for name, best_model, best_params, cv_auc in results:\n",
    "    out = evaluateModel(best_model, X_train, y_train, X_test, y_test, name=name, refit=False, positive_label=1)\n",
    "    rows.append({\n",
    "        \"Model\": name,\n",
    "        \"Val Accuracy\": out[\"Accuracy\"],\n",
    "        \"Val Precision\": out[\"Precision\"],\n",
    "        \"Val Recall\": out[\"Recall\"],\n",
    "        \"Val F1\": out[\"F1 Score\"],\n",
    "        \"Val ROC AUC\": out[\"ROC AUC\"],\n",
    "        \"CV ROC AUC (best)\": cv_auc,\n",
    "        \"Best Params\": best_params\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_report = pd.DataFrame(rows).sort_values(\"Val ROC AUC\", ascending=False)\n",
    "grid_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter fine-tuning with RandomForest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search around the current settings defined in RandomForestClassifier model `rf`\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 800],              # try a bit larger forests\n",
    "    'max_depth': [8, 10, None],                   # keep shallow vs deep\n",
    "    'min_samples_leaf': [20, 30, 50],             # slightly smaller/larger leaves\n",
    "    'min_samples_split': [30, 50, 70],            # slightly smaller/larger splits\n",
    "    'max_features': ['sqrt', 0.5, None],          # vary feature sampling\n",
    "    'criterion': ['gini', 'log_loss']             # try log_loss for prob calibration\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_log_loss',  # optimizing for better probability quality\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Rebulid the RF Classifier with the optimized parameters from GridSeacrCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "                'criterion': 'log_loss',\n",
    "                'max_depth': None,\n",
    "                'max_features': None,\n",
    "                'min_samples_leaf': 20,\n",
    "                'min_samples_split': 30,\n",
    "                'n_estimators': 800\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(\n",
    "                                    random_state=42,\n",
    "                                    class_weight='balanced',\n",
    "                                    n_jobs=-1,\n",
    "                                    bootstrap=True,\n",
    "                                    **best_params\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_best_rf = evaluateModel(best_rf, X_train, y_train, X_test, y_test, name=\"RandomForest (Grid - neg_log_loss)\", refit=False, positive_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = result_best_rf[\"y_prob\"]           # probs for class 1 from evaluate_model\n",
    "prec, rec, thr = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "# Best-F1 threshold\n",
    "f1 = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
    "best_idx = np.argmax(f1)\n",
    "best_thr = thr[best_idx]\n",
    "print(\"Best-F1 threshold:\", best_thr, \"F1:\", f1[best_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply custom threshold\n",
    "y_pred_opt = (y_prob >= best_thr).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_metrics = {\n",
    "    \"Accuracy\": (y_pred_opt == y_test).mean(),\n",
    "    \"Precision\": precision_score(y_test, y_pred_opt, zero_division=0),\n",
    "    \"Recall\": recall_score(y_test, y_pred_opt, zero_division=0),\n",
    "    \"F1 Score\": f1_score(y_test, y_pred_opt, zero_division=0),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_prob),\n",
    "    \"Confusion Matrix\": confusion_matrix(y_test, y_pred_opt)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "cal_rf = CalibratedClassifierCV(best_rf, method=\"isotonic\", cv=5)\n",
    "cal_rf.fit(X_train, y_train)\n",
    "\n",
    "res_rf_cal = evaluateModel(\n",
    "    cal_rf, X_train, y_train, X_test, y_test,\n",
    "    name=\"RandomForest (Calibrated - neg_log_loss)\",\n",
    "    refit=False, positive_label=1\n",
    ")\n",
    "res_rf_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrices = pd.DataFrame([result_lr_orig, result_lr_smote, result_lr_nm, result_dt_orig, result_dt_smote, result_dt_nm, result_rf_orig, result_rf_smote, result_rf_nm, result_svc_orig, result_svc_smote, result_svc_nm, result_xgb_orig, result_xgb_smote, result_xgb_nm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy in Classification Models\n",
    "\n",
    "**Accuracy** is a commonly used evaluation metric in classification tasks. It measures the **proportion of correct predictions** (both true positives and true negatives) over the **total number of predictions**.\n",
    "\n",
    "### Formula\n",
    "\n",
    "\\[\n",
    "\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- **TP**: True Positives – Model correctly predicts class 1\n",
    "- **TN**: True Negatives – Model correctly predicts class 0\n",
    "- **FP**: False Positives – Model incorrectly predicts class 1\n",
    "- **FN**: False Negatives – Model incorrectly predicts class 0\n",
    "\n",
    "---\n",
    "\n",
    "### Example\n",
    "\n",
    "Imagine a binary classification task with the following confusion matrix:\n",
    "\n",
    "|               | Predicted 0 | Predicted 1 |\n",
    "|---------------|-------------|-------------|\n",
    "| **Actual 0**  |     90      |      10     |\n",
    "| **Actual 1**  |     30      |      70     |\n",
    "\n",
    "In this case:\n",
    "- TP = 70\n",
    "- TN = 90\n",
    "- FP = 10\n",
    "- FN = 30\n",
    "\n",
    "So,\n",
    "\n",
    "\\[\n",
    "\\text{Accuracy} = \\frac{70 + 90}{70 + 90 + 10 + 30} = \\frac{160}{200} = 0.80\n",
    "\\]\n",
    "\n",
    "The model has an **accuracy of 80%**.\n",
    "\n",
    "---\n",
    "\n",
    "### When Accuracy Can Be Misleading\n",
    "\n",
    "Accuracy can be **misleading when classes are imbalanced**.\n",
    "\n",
    "Example: If 95% of samples are class 0, a model that always predicts class 0 will have 95% accuracy – but **zero recall and precision for class 1** (the minority class). Hence, **other metrics like F1 Score or ROC AUC** are preferred in such cases.\n",
    "\n",
    "---\n",
    "\n",
    "### Use Accuracy When:\n",
    "- Classes are balanced\n",
    "- Both false positives and false negatives carry equal cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot the Accuracies of the different models\n",
    "# Sort models by Accuracy for better visualization\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(model_metrices.sort_values(by=\"Accuracy\", ascending=True)[\"Model\"], model_metrices.sort_values(by=\"Accuracy\", ascending=True)[\"Accuracy\"], color=\"dimgray\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.title(\"Model Accuracy Comparison (Kaggle Test Set)\")\n",
    "plt.grid(axis='x', linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Annotate bars\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.005, bar.get_y() + bar.get_height() / 2, f\"{width:.2f}\", va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision in Classification Models\n",
    "\n",
    "**Precision** is a metric that tells us **how many of the predicted positive instances were actually positive**. It answers the question:\n",
    "\n",
    "> _\"When the model predicts positive (class = 1), how often is it correct?\"_\n",
    "\n",
    "---\n",
    "\n",
    "### Formula\n",
    "\n",
    "\\[\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- **TP (True Positives)**: Model correctly predicts class 1\n",
    "- **FP (False Positives)**: Model incorrectly predicts class 1 when it's actually 0\n",
    "\n",
    "---\n",
    "\n",
    "### Example\n",
    "\n",
    "Imagine this confusion matrix for a binary classifier:\n",
    "\n",
    "|               | Predicted 0 | Predicted 1 |\n",
    "|---------------|-------------|-------------|\n",
    "| **Actual 0**  |     85      |      15     |\n",
    "| **Actual 1**  |     30      |      70     |\n",
    "\n",
    "- **TP = 70** (actual 1, predicted 1)\n",
    "- **FP = 15** (actual 0, predicted 1)\n",
    "\n",
    "\\[\n",
    "\\text{Precision} = \\frac{70}{70 + 15} = \\frac{70}{85} \\approx 0.82\n",
    "\\]\n",
    "\n",
    "The precision is **82%**, meaning 82% of all predictions for the positive class were correct.\n",
    "\n",
    "---\n",
    "\n",
    "### When to Focus on Precision\n",
    "\n",
    "Use **Precision** when:\n",
    "- **False positives are costly** (e.g., in spam detection, a non-spam email predicted as spam is annoying).\n",
    "- You want to **minimize false alarms**.\n",
    "\n",
    "### NOTE\n",
    "\n",
    "High precision doesn't mean high recall. You can have **high precision but low recall** if the model is very selective in predicting positives.\n",
    "\n",
    "---\n",
    "\n",
    "### Use Precision When:\n",
    "- You want **fewer false positives**\n",
    "- Examples: Spam filters, medical tests for rare diseases, fraud detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot the Precision of the different models\n",
    "# Sort models by Accuracy for better visualization\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(model_metrices.sort_values(by=\"Precision\", ascending=True)[\"Model\"], model_metrices.sort_values(by=\"Precision\", ascending=True)[\"Precision\"], color=\"dimgray\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.title(\"Model Precision Comparison (Kaggle Test Set)\")\n",
    "plt.grid(axis='x', linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Annotate bars\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.005, bar.get_y() + bar.get_height() / 2, f\"{width:.2f}\", va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall in Classification Models\n",
    "\n",
    "**Recall** (also known as **Sensitivity** or **True Positive Rate**) measures the ability of a model to identify **all relevant instances** of a class.\n",
    "\n",
    "It answers the question:\n",
    "\n",
    "> _\"Of all the actual positives, how many did the model correctly identify?\"_\n",
    "\n",
    "---\n",
    "\n",
    "### Formula\n",
    "\n",
    "\\[\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- **TP (True Positives)**: Correctly predicted positive cases\n",
    "- **FN (False Negatives)**: Actual positives incorrectly predicted as negatives\n",
    "\n",
    "---\n",
    "\n",
    "### Example\n",
    "\n",
    "Using the following confusion matrix:\n",
    "\n",
    "|               | Predicted 0 | Predicted 1 |\n",
    "|---------------|-------------|-------------|\n",
    "| **Actual 0**  |     85      |      15     |\n",
    "| **Actual 1**  |     30      |      70     |\n",
    "\n",
    "- **TP = 70**  \n",
    "- **FN = 30**\n",
    "\n",
    "\\[\n",
    "\\text{Recall} = \\frac{70}{70 + 30} = \\frac{70}{100} = 0.70\n",
    "\\]\n",
    "\n",
    "So the recall is **70%**, meaning the model identified 70% of all actual positive cases.\n",
    "\n",
    "---\n",
    "\n",
    "### When to Focus on Recall\n",
    "\n",
    "Use **Recall** when:\n",
    "- **False negatives are costly**  \n",
    "- You're okay with capturing more false positives, but want to **avoid missing any actual positives**\n",
    "\n",
    "### Tip\n",
    "\n",
    "You can have **high recall but low precision** if the model predicts too many positives (including wrong ones).\n",
    "\n",
    "---\n",
    "\n",
    "### Use Recall When:\n",
    "- You want **fewer false negatives**\n",
    "- Examples: Cancer detection, fraud detection, system alarms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot the Recall of the different models\n",
    "# Sort models by Recall for better visualization\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(model_metrices.sort_values(by=\"Recall\", ascending=True)[\"Model\"], model_metrices.sort_values(by=\"Recall\", ascending=True)[\"Recall\"], color=\"dimgray\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Model Recall Comparison (Kaggle Test Set)\")\n",
    "plt.grid(axis='x', linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Annotate bars\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.005, bar.get_y() + bar.get_height() / 2, f\"{width:.2f}\", va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score in Classification Models\n",
    "\n",
    "**F1 Score** is the **harmonic mean** of **Precision** and **Recall**, offering a balanced metric when you want to consider both false positives and false negatives.\n",
    "\n",
    "It is particularly useful in **imbalanced classification problems**, where one class occurs more frequently than the other.\n",
    "\n",
    "---\n",
    "\n",
    "### Formula\n",
    "\n",
    "\\[\n",
    "\\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### Example\n",
    "\n",
    "Let’s say your model has:\n",
    "- **Precision = 0.82**\n",
    "- **Recall = 0.70**\n",
    "\n",
    "\\[\n",
    "\\text{F1 Score} = 2 \\times \\frac{0.82 \\times 0.70}{0.82 + 0.70} = 2 \\times \\frac{0.574}{1.52} \\approx 0.755\n",
    "\\]\n",
    "\n",
    "So the **F1 Score is 0.755**, representing a trade-off between precision and recall.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Harmonic Mean?\n",
    "\n",
    "The harmonic mean punishes extreme values more than the arithmetic mean. For example:\n",
    "- If precision is 1.0 but recall is 0.0 → F1 = 0.0\n",
    "- If precision and recall are both 0.5 → F1 = 0.5\n",
    "\n",
    "Thus, F1 is high **only when both precision and recall are reasonably high**.\n",
    "\n",
    "---\n",
    "\n",
    "### Use F1 Score When:\n",
    "- You want a **balance between precision and recall**\n",
    "- The **class distribution is imbalanced**\n",
    "- Examples: Fraud detection, medical diagnosis, anomaly detection\n",
    "\n",
    "---\n",
    "\n",
    "### F1 Score vs Accuracy\n",
    "\n",
    "In imbalanced datasets, **accuracy may be misleading**, while **F1 Score gives better insight** into model performance on the minority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot the F1 Score of the different models\n",
    "# Sort models by Recall for better visualization\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(model_metrices.sort_values(by=\"F1 Score\", ascending=True)[\"Model\"], model_metrices.sort_values(by=\"F1 Score\", ascending=True)[\"F1 Score\"], color=\"dimgray\")\n",
    "plt.xlabel(\"F1 Score\")\n",
    "plt.title(\"Model F1 Score Comparison (Kaggle Test Set)\")\n",
    "plt.grid(axis='x', linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Annotate bars\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.005, bar.get_y() + bar.get_height() / 2, f\"{width:.2f}\", va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC AUC Score (Receiver Operating Characteristic – Area Under Curve)\n",
    "\n",
    "**ROC AUC** is a powerful metric that evaluates how well a binary classification model distinguishes between two classes.\n",
    "\n",
    "- **ROC Curve** plots the **True Positive Rate (Recall)** against the **False Positive Rate** at various threshold settings.\n",
    "- **AUC (Area Under the Curve)** summarizes the curve into a single number between **0 and 1**.\n",
    "\n",
    "---\n",
    "\n",
    "### Formula (Conceptual)\n",
    "\n",
    "- **True Positive Rate (TPR)** = Recall = TP / (TP + FN)\n",
    "- **False Positive Rate (FPR)** = FP / (FP + TN)\n",
    "\n",
    "The **ROC curve** is plotted by:\n",
    "- Varying the decision threshold (e.g., from 0.0 to 1.0)\n",
    "- Calculating TPR and FPR for each threshold\n",
    "\n",
    "\\[\n",
    "\\text{AUC} = \\int_0^1 TPR(FPR^{-1}(x)) \\, dx\n",
    "\\]\n",
    "\n",
    "This integral represents the **probability that a randomly chosen positive example ranks higher than a randomly chosen negative one**.\n",
    "\n",
    "---\n",
    "\n",
    "### Example (Interpretation)\n",
    "\n",
    "| AUC Score | Interpretation               |\n",
    "|-----------|-------------------------------|\n",
    "| 0.5       | No discrimination (random)    |\n",
    "| 0.6–0.7   | Poor                          |\n",
    "| 0.7–0.8   | Fair                          |\n",
    "| 0.8–0.9   | Good                          |\n",
    "| 0.9–1.0   | Excellent                     |\n",
    "\n",
    "- A model with **AUC = 0.85** is likely to rank a positive instance higher than a negative instance **85% of the time**.\n",
    "\n",
    "---\n",
    "\n",
    "### Use ROC AUC When:\n",
    "- You want to **evaluate classification performance across all thresholds**\n",
    "- You are dealing with **imbalanced data**\n",
    "- You want to **compare multiple models objectively**\n",
    "\n",
    "---\n",
    "\n",
    "### Caution\n",
    "- ROC AUC assumes ranking ability — it doesn’t tell you where your decision threshold should be.\n",
    "- In extremely imbalanced datasets, **Precision-Recall AUC** may be more informative.\n",
    "\n",
    "---\n",
    "\n",
    "### Visualization Tip\n",
    "A perfect model has an AUC of **1.0** with the curve passing through the **top-left corner** (TPR = 1, FPR = 0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot the ROC AUC of the different models\n",
    "# Sort models by Recall for better visualization\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(model_metrices.sort_values(by=\"ROC AUC\", ascending=True)[\"Model\"], model_metrices.sort_values(by=\"ROC AUC\", ascending=True)[\"ROC AUC\"], color=\"dimgray\")\n",
    "plt.xlabel(\"ROC AUC\")\n",
    "plt.title(\"Model ROC AUC Comparison (Kaggle Test Set)\")\n",
    "plt.grid(axis='x', linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Annotate bars\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.005, bar.get_y() + bar.get_height() / 2, f\"{width:.2f}\", va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Plot Feature Importance?\n",
    "\n",
    "Feature importance helps to:\n",
    "1. **Understand model behavior** – See which variables the model relies on most.\n",
    "2. **Interpretability** – Gain trust in the model by identifying key decision drivers.\n",
    "3. **Feature selection** – Reduce dimensionality by eliminating less important features.\n",
    "4. **Improve performance** – Remove noisy or irrelevant features to improve generalization.\n",
    "5. **Communicate results** – Visuals of top features help stakeholders make data-driven decisions.\n",
    "\n",
    "---\n",
    "\n",
    "### How It Works\n",
    "\n",
    "For models like:\n",
    "- **Decision Trees, Random Forest, XGBoost**: Importance is based on how much a feature decreases impurity (e.g., Gini, Entropy).\n",
    "- **Linear Models**: Coefficients represent weights (magnitude matters, but scale needs normalization).\n",
    "- **SHAP/Permutation**: Model-agnostic approaches that evaluate feature impact more robustly.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Insight\n",
    "\n",
    "> If **\"Interest Rate\"** and **\"Loan Amount\"** are top features in predicting default, the bank can revise loan approval criteria or interest policies accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practice\n",
    "\n",
    "After training your model (especially tree-based):\n",
    "- Use `.feature_importances_` (Random Forest, XGBoost)\n",
    "- Sort and plot top N features\n",
    "- Optionally use SHAP for deeper interpretability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "We compare the top 10 most important features across the following models:\n",
    "- Random Forest (Original)\n",
    "- Random Forest (SMOTE)\n",
    "- Random Forest (NearMiss)\n",
    "- SVC (using permutation importance or SHAP)\n",
    "- Decision Tree (for comparison)\n",
    "\n",
    "This helps us assess which features are consistently influential and whether resampling changes feature reliance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance: Random Forest (Original)\n",
    "\n",
    "Understanding which features influence model predictions is essential, especially when using tree-based algorithms like Random Forest. \n",
    "\n",
    "We use `.feature_importances_` to extract the importance score of each feature. These scores are derived from the **average reduction in impurity** (e.g., Gini) contributed by each feature across all trees in the forest.\n",
    "\n",
    "Below, we plot the **Top 10 most important features** from the **Random Forest model trained on the original data** (before SMOTE or NearMiss).\n",
    "\n",
    "This helps us:\n",
    "- Interpret model behavior\n",
    "- Identify key drivers of loan default\n",
    "- Prepare for further feature selection and comparison\n",
    "\n",
    "We’ll later compare this with feature importance plots from SMOTE and NearMiss models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 1: Filter tree-based models with valid feature importance ===\n",
    "tree_models = model_metrices[model_metrices[\"Feature Importance\"].notnull()].copy()\n",
    "\n",
    "# === Step 2: Plot each model's top N important features ===\n",
    "N = 10  # Top N features to display (change if needed)\n",
    "feature_names = X_full.columns  # Ensure you're using correct feature list\n",
    "\n",
    "for idx, row in tree_models.iterrows():\n",
    "    importances = np.array(row[\"Feature Importance\"])\n",
    "    \n",
    "    # Get indices of top N features\n",
    "    top_idx = np.argsort(importances)[-N:][::-1]\n",
    "    top_features = feature_names[top_idx]\n",
    "    top_importances = importances[top_idx]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.barh(top_features[::-1], top_importances[::-1])  # Reversed for descending bars\n",
    "    plt.title(f\"Feature Importance: {row['Model']}\")\n",
    "    plt.xlabel(\"Importance Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning: Support Vector Classifier (SVC) with SMOTE\n",
    "\n",
    "To improve the performance of our best-performing model (SVC with SMOTE), we use **GridSearchCV** to find the optimal combination of hyperparameters.\n",
    "\n",
    "### Why Tune?\n",
    "SVC is sensitive to hyperparameters such as:\n",
    "- `C`: Regularization strength\n",
    "- `kernel`: Linear vs. nonlinear boundaries (e.g., 'linear', 'rbf')\n",
    "- `gamma`: Controls influence of points (for 'rbf' kernel)\n",
    "\n",
    "### Steps\n",
    "1. **Define Parameter Grid** for exploration.\n",
    "2. **Fit GridSearchCV** on resampled training data.\n",
    "3. **Evaluate** on the Kaggle-style test set.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline: SMOTE + SVC\n",
    "svc_pipeline = ImbPipeline([\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"svc\", SVC(probability=True, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define param grid\n",
    "param_grid = {\n",
    "    \"svc__C\": [0.1, 1, 10],\n",
    "    \"svc__kernel\": [\"linear\", \"rbf\"],\n",
    "    \"svc__gamma\": [\"scale\", \"auto\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_encoded.drop(columns=[\"Loan Status\"])\n",
    "y = df_train_encoded[\"Loan Status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "grid_svc = GridSearchCV(svc_pipeline, param_grid, cv=5, scoring=\"f1\", verbose=1, n_jobs=-1)\n",
    "grid_svc.fit(X, y)  # X and y = original train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Step 1: Subsample for tuning (10K examples, stratified)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=10000, random_state=42)\n",
    "for small_idx, _ in sss.split(X, y):\n",
    "    X_small, y_small = X.iloc[small_idx], y.iloc[small_idx]\n",
    "\n",
    "# Step 2: Define pipeline\n",
    "svc_pipeline = ImbPipeline([\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"svc\", SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Step 3: Refined param grid (only 4 fits now)\n",
    "param_grid = {\n",
    "    \"svc__C\": [1, 10],\n",
    "    \"svc__kernel\": [\"rbf\"],\n",
    "    \"svc__gamma\": [\"scale\"]\n",
    "}\n",
    "\n",
    "# Step 4: Grid Search (CV=3)\n",
    "grid_svc = GridSearchCV(\n",
    "    svc_pipeline, \n",
    "    param_grid, \n",
    "    cv=3, \n",
    "    scoring=\"f1\", \n",
    "    verbose=3, \n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_svc.fit(X_small, y_small)\n",
    "\n",
    "# Step 5: Best Params + Score\n",
    "print(\"✅ Best Params:\", grid_svc.best_params_)\n",
    "print(\"🎯 Best F1 Score on subset:\", grid_svc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = df_train_encoded.drop(columns=[\"Loan Status\"])\n",
    "y = df_train_encoded[\"Loan Status\"]\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "param_grid = {'max_depth': [3,4,5], 'max_features': ['int','float','auto','log2']} \n",
    "modelgrid= GridSearchCV(RandomForestClassifier(),param_grid,refit=True,verbose=3, cv=cv, scoring='neg_log_loss')\n",
    "modelgrid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Define features and target\n",
    "X = df_train_encoded.drop(columns=[\"Loan Status\"])\n",
    "y = df_train_encoded[\"Loan Status\"]\n",
    "\n",
    "# Use Stratified K-Fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None]  # Correct options for max_features\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "modelgrid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    refit=True,\n",
    "    verbose=3,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_log_loss\",  # Change scoring metric here as needed\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "modelgrid.fit(X, y)\n",
    "\n",
    "# Output best parameters and score\n",
    "print(\" Best Parameters:\", modelgrid.best_params_)\n",
    "print(\" Best Score (neg_log_loss):\", modelgrid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Define X and y from original training data\n",
    "X = df_train_encoded.drop(columns=[\"Loan Status\"])\n",
    "y = df_train_encoded[\"Loan Status\"]\n",
    "\n",
    "# Define Stratified K-Fold for balanced validation\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Define pipeline: SMOTE + SVC\n",
    "svc_pipeline = ImbPipeline([\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"svc\", SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Define a tighter param grid to speed up computation\n",
    "param_grid = {\n",
    "    \"svc__C\": [1, 10],\n",
    "    \"svc__kernel\": [\"linear\", \"rbf\"],\n",
    "    \"svc__gamma\": [\"scale\"]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_svc = GridSearchCV(\n",
    "    svc_pipeline,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",\n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_svc.fit(X, y)\n",
    "\n",
    "# Best model\n",
    "print(\"✅ Best Parameters:\", grid_svc.best_params_)\n",
    "print(\"✅ Best F1 Score:\", grid_svc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📤 Final Submission Generation\n",
    "\n",
    "After training and tuning the `RandomForestClassifier`, we generate the final predictions for the test set and prepare a CSV file for submission.\n",
    "\n",
    "**Steps:**\n",
    "1. Predict loan default status using the best model from GridSearchCV.\n",
    "2. Combine predictions with the test set IDs.\n",
    "3. Save the final DataFrame as `final_submission.csv`.\n",
    "\n",
    "This file is now ready to be submitted or used for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load test.csv to retrieve the ID column\n",
    "original_test = pd.read_csv(\"test.csv\")  # Adjust path if needed\n",
    "\n",
    "# Generate submission using original IDs\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": original_test[\"ID\"],\n",
    "    \"Loan Status\": y_pred_final\n",
    "})\n",
    "\n",
    "submission.to_csv(\"final_submission.csv\", index=False)\n",
    "print(\"✅ Submission file created using reloaded test.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 📌 Feature Importance Plot for Final Random Forest Model\n",
    "\n",
    "# Extract trained model from GridSearchCV\n",
    "final_rf = modelgrid.best_estimator_\n",
    "\n",
    "# Get feature importances\n",
    "importances = final_rf.feature_importances_\n",
    "feature_names = X.columns  # Make sure this matches the columns used in training\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "importances_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display Top 20 Features\n",
    "top_n = 20\n",
    "top_features = importances_df.head(top_n)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=top_features, palette=\"viridis\")\n",
    "plt.title(f\"🔍 Top {top_n} Important Features - Random Forest\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Feature Importance: Random Forest Classifier\n",
    "\n",
    "The plot below illustrates the top features that contributed most to the predictions of the final model, based on the feature importance scores from the trained Random Forest Classifier.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "### 🎯 Why it matters:\n",
    "- Helps explain the **drivers of loan default prediction**\n",
    "- Offers **transparency** for business or regulatory reporting\n",
    "- Can inform **feature selection** for future modeling\n",
    "\n",
    "### 🛠️ Method:\n",
    "- We extracted `.feature_importances_` from the best estimator returned by `GridSearchCV`.\n",
    "- We visualized the **top 20 most influential features**.\n",
    "\n",
    "### 📈 Insights: Top 20 Features Driving Loan Default Prediction\n",
    "\n",
    "From the plot above, we can observe several key insights about the features contributing most to the model’s decisions:\n",
    "\n",
    "1. **💥 Total Collection Amount**  \n",
    "   - This is the most important feature. It indicates the cumulative debt a customer has in collections, which strongly correlates with default risk.\n",
    "\n",
    "2. **💰 Loan Amount**  \n",
    "   - The size of the loan also ranks high. Larger loan requests may signal higher financial risk.\n",
    "\n",
    "3. **💸 Collection Recovery Fee & Total Received Late Fee**  \n",
    "   - These metrics reflect historical delinquency or fees incurred, showing strong predictive power.\n",
    "\n",
    "4. **📊 Revolving Utilities, Interest Rate, and Revolving Balance**  \n",
    "   - These are indicators of credit card utilization and ongoing liabilities, which reflect a borrower's debt behavior.\n",
    "\n",
    "5. **🏦 Funded Amount & Funded Amount by Investor**  \n",
    "   - These provide context on the confidence and investment made in the borrower.\n",
    "\n",
    "6. **🧾 Debt to Income**  \n",
    "   - A classic metric in credit scoring, showing the borrower's ability to manage debt based on income.\n",
    "\n",
    "7. **🏠 Home Ownership & Total Current Balance**  \n",
    "   - Suggest that asset ownership and total liabilities play a substantial role in predicting defaults.\n",
    "\n",
    "8. **💳 Total Revolving Credit Limit & Total Received Interest**  \n",
    "   - Provide insight into credit availability and how much a borrower is already repaying.\n",
    "\n",
    "9. **📋 Loan Title, Sub Grade, Term**  \n",
    "   - While less important than financial indicators, these represent administrative or classification details that add additional context to risk.\n",
    "\n",
    "### 🧠 Conclusion\n",
    "The model relies heavily on **credit behavior, past delinquency**, and **loan characteristics** to predict loan defaults. Surprisingly, traditional demographic fields (like Employment Duration or Verification Status) didn't surface in the top 20 — likely because financial variables dominate in signal strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Predict\n",
    "y_pred = modelgrid.best_estimator_.predict(X_kaggle_test)\n",
    "y_prob = modelgrid.best_estimator_.predict_proba(X_kaggle_test)[:, 1]\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_kaggle_test, y_pred)\n",
    "print(\"🔍 Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "print(\"📋 Classification Report:\\n\", classification_report(y_kaggle_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n",
    "                              display_labels=[\"Non-Defaulter\", \"Defaulter\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Error Analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to original test set\n",
    "df_errors = df_test_encoded.copy()\n",
    "df_errors[\"Actual\"] = y_kaggle_test\n",
    "df_errors[\"Predicted\"] = y_pred\n",
    "df_errors[\"Probability\"] = y_prob\n",
    "\n",
    "# False Positives (Predicted 1 but Actual 0)\n",
    "false_positives = df_errors[(df_errors[\"Actual\"] == 0) & (df_errors[\"Predicted\"] == 1)]\n",
    "\n",
    "# False Negatives (Predicted 0 but Actual 1)\n",
    "false_negatives = df_errors[(df_errors[\"Actual\"] == 1) & (df_errors[\"Predicted\"] == 0)]\n",
    "\n",
    "print(f\"🔺 False Positives: {len(false_positives)}\")\n",
    "print(f\"🔻 False Negatives: {len(false_negatives)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=false_negatives, x=\"Actual\", y=\"Loan Amount\")\n",
    "plt.title(\"Loan Amount in False Negatives\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📉 Error Analysis of Final Random Forest Model\n",
    "\n",
    "### 🔹 Confusion Matrix\n",
    "\n",
    "The confusion matrix shows a **serious imbalance** in prediction, where all test samples are predicted as **Non-Defaulter (class 0)**, regardless of their actual class:\n",
    "\n",
    "|                  | Predicted: Non-Defaulter | Predicted: Defaulter |\n",
    "|------------------|--------------------------|-----------------------|\n",
    "| **Actual: Non-Defaulter** | 15,300                   | 0                     |\n",
    "| **Actual: Defaulter**     | 13,613                   | 0                     |\n",
    "\n",
    "- 🔺 **False Positives** (Predicted as Defaulter but actually Non-Defaulter): `0`  \n",
    "- 🔻 **False Negatives** (Predicted as Non-Defaulter but actually Defaulter): `13,613`\n",
    "\n",
    "This suggests **extreme bias** in the model toward the majority class.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 False Negatives (Defaulters missed)\n",
    "\n",
    "A box plot was generated for **Loan Amount** in false negatives. Key insights:\n",
    "\n",
    "- The **median loan amount** of missed defaulters is relatively high (~\\$12,500).\n",
    "- The **range of loan amounts** is wide, indicating **no specific amount range** is exclusively being misclassified.\n",
    "- From a **financial risk perspective**, these false negatives could represent **significant loss exposure**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 Takeaways\n",
    "\n",
    "- Despite resampling and tuning, the model **fails to capture minority class (Defaulters)**.\n",
    "- Class imbalance still persists post-SMOTE, or the model is **too risk-averse**, defaulting to the safe class.\n",
    "- 🛠️ **Recommendations to improve performance**:\n",
    "  - Use `class_weight=\"balanced\"` in models like Logistic Regression, Decision Trees, or Random Forest.\n",
    "  - Consider **threshold tuning** instead of default `0.5`.\n",
    "  - Explore **advanced models** like XGBoost, LightGBM, or CatBoost.\n",
    "  - Perform further **feature selection/engineering** to better differentiate the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Step 1: Class Weighting in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Import and Prepare ---\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define your training and test sets\n",
    "X = df_train_encoded.drop(columns=[\"Loan Status\"])\n",
    "y = df_train_encoded[\"Loan Status\"]\n",
    "X_test = df_test_encoded.drop(columns=[\"Loan Status\"])\n",
    "y_test = df_target[\"Loan Status\"]\n",
    "\n",
    "# Check how many NaNs exist in y_test\n",
    "print(\"NaNs in y_test:\", y_test.isna().sum())\n",
    "\n",
    "# Drop or fix them\n",
    "# Option 1: Drop rows with NaN in y_test and update X_test accordingly\n",
    "valid_idx = y_test.dropna().index\n",
    "X_test_clean = X_test.loc[valid_idx]\n",
    "y_test_clean = y_test.loc[valid_idx]\n",
    "\n",
    "# --- 2. Train RandomForest with Balanced Class Weights ---\n",
    "rf_balanced = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "rf_balanced.fit(X, y)\n",
    "\n",
    "# --- 3. Predict and Evaluate ---\n",
    "y_pred_balanced = rf_balanced.predict(X_test)\n",
    "\n",
    "print(\"📊 Classification Report - Class Weighted Random Forest\")\n",
    "print(classification_report(y_test, y_pred_balanced))\n",
    "\n",
    "# --- 4. Confusion Matrix ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_balanced)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Defaulter\", \"Defaulter\"], yticklabels=[\"Non-Defaulter\", \"Defaulter\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Random Forest with Class Weights\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Step 1: Class Weighting in Random Forest\n",
    "\n",
    "### What We Did:\n",
    "We trained a `RandomForestClassifier` with `class_weight=\"balanced\"` to automatically adjust for class imbalance. This gives more importance to the minority class (Defaulters), ensuring that the model doesn't ignore them.\n",
    "\n",
    "### Code Snippet:\n",
    "```python\n",
    "rf_balanced = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "rf_balanced.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize\n",
    "thresholds = np.linspace(0.0, 1.0, 100)\n",
    "f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "threshold_results = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_thresh = (y_probs >= t).astype(int)\n",
    "    f1_scores.append(f1_score(y_test, y_pred_thresh))\n",
    "    precisions.append(precision_score(y_test, y_pred_thresh, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred_thresh))\n",
    "    threshold_results.append((t, f1_score(y_test, y_pred_thresh), precision_score(y_test, y_pred_thresh, zero_division=0), recall_score(y_test, y_pred_thresh)))\n",
    "\n",
    "# Data frame\n",
    "#print (threshold_df)\n",
    "threshold_df = pd.DataFrame(threshold_results, columns=[\"Threshold\", \"F1 Score\", \"Precision\", \"Recall\"])\n",
    "#display(threshold_df)\n",
    "print (threshold_df.sort_values(by=\"F1 Score\", ascending=False).head(10))\n",
    "#print (threshold_df.head(5))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, f1_scores, label=\"F1 Score\", color=\"blue\")\n",
    "plt.plot(thresholds, precisions, label=\"Precision\", linestyle=\"--\", color=\"green\")\n",
    "plt.plot(thresholds, recalls, label=\"Recall\", linestyle=\"--\", color=\"orange\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision, Recall and F1 Score vs Threshold\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Best threshold\n",
    "#best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "#print(f\"✅ Best Threshold for Max F1 Score: {best_threshold:.2f}\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Threshold Optimization for Imbalanced Classification\n",
    "\n",
    "In binary classification problems, especially when dealing with **imbalanced datasets**, the default threshold of `0.5` used to convert probabilities into class predictions may not yield optimal performance. A better threshold can often improve **recall**, **precision**, or **F1-score**, depending on what the use-case prioritizes.\n",
    "\n",
    "### 🧠 Concept\n",
    "\n",
    "- By default, classifiers like `RandomForestClassifier` output probabilities for each class.\n",
    "- We usually predict class `1` (defaulter) if probability > 0.5.\n",
    "- But in imbalanced problems, adjusting this threshold helps find a better balance between:\n",
    "  - **Precision**: Out of predicted defaulters, how many were actually defaulters?\n",
    "  - **Recall**: Out of all actual defaulters, how many did we correctly predict?\n",
    "  - **F1 Score**: Harmonic mean of precision and recall.\n",
    "\n",
    "### 📈 Approach\n",
    "\n",
    "1. Vary the classification threshold from 0.0 to 1.0 (in steps).\n",
    "2. For each threshold, compute:\n",
    "   - F1 Score\n",
    "   - Precision\n",
    "   - Recall\n",
    "3. Plot them to observe the trade-off.\n",
    "4. Select the threshold that gives **maximum F1 Score** (or whichever metric is critical).\n",
    "\n",
    "### 📊 Result\n",
    "\n",
    "From our plot, we found:\n",
    "\n",
    "- **Best threshold (max F1)**: `0.00`\n",
    "- That means: for this model, **any predicted probability > 0.00** is classified as `1`, i.e., extremely lenient.\n",
    "\n",
    "This makes sense in our case because our model was heavily biased toward classifying all samples as non-defaulters (`0`). Setting the threshold lower allows the model to finally label some examples as defaulters.\n",
    "\n",
    "### 🔍 Plot\n",
    "\n",
    "The graph below illustrates how precision, recall, and F1 Score change as the threshold increases:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Next Step\n",
    "\n",
    "Now that we’ve found the optimal threshold, we can **re-evaluate the model’s predictions** on the test set using this threshold to **compare improvements in F1 or Recall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Set Best Threshold (optional: test slightly higher ones if needed) ---\n",
    "best_threshold = 0.00\n",
    "\n",
    "# --- 2. Predict using Probabilities ---\n",
    "y_probs = rf_balanced.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "y_pred_final = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# --- 3. Evaluation ---\n",
    "print(\"📌 Updated Evaluation using Best Threshold\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "print(\"🧱 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Final Evaluation with Threshold Optimization\n",
    "\n",
    "We applied a custom decision threshold of **0.00** to maximize recall and F1 score. Here's the classification report after threshold adjustment:\n",
    "\n",
    "- **Why adjust threshold?**\n",
    "  Logistic models and tree-based models output probabilities. By default, the decision threshold is `0.5`, but that might not be optimal, especially for imbalanced datasets. Lowering the threshold helps us **identify more defaulters (higher recall)** at the cost of some precision.\n",
    "\n",
    "- **How this helps?**\n",
    "  In financial risk modeling, missing a defaulter is **more costly** than incorrectly labeling a non-defaulter. Threshold tuning lets us **balance precision and recall** based on the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 🔍 Interpretation:\n",
    "- **All predictions were labeled as defaulters (`class 1`)**.\n",
    "- Therefore, **recall is 1.00** (we caught *all* actual defaulters).\n",
    "- However, **precision is low (0.47)** because all non-defaulters were wrongly classified.\n",
    "- **No true negatives**: model failed to identify any non-defaulter.\n",
    "\n",
    "### ⚠️ Observation:\n",
    "Using a threshold of `0.00` means **even the lowest probability** of being a defaulter is treated as a defaulter, resulting in:\n",
    "- **Maximum recall**\n",
    "- **Zero precision for class 0**\n",
    "\n",
    "### 🧠 Insight:\n",
    "This result **prioritizes catching all defaulters** (very useful in high-stakes risk assessment), but at the cost of misclassifying every non-defaulter.\n",
    "\n",
    "### ✅ Recommendation:\n",
    "Try a **slightly higher threshold (e.g., 0.05 to 0.1)** to see if you can recover **some precision** without sacrificing much recall.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Set Best Threshold (optional: test slightly higher ones if needed) ---\n",
    "best_threshold = 0.08\n",
    "\n",
    "# --- 2. Predict using Probabilities ---\n",
    "y_probs = rf_balanced.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "y_pred_final = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# --- 3. Evaluation ---\n",
    "print(\"📌 Updated Evaluation using Best Threshold\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "print(\"🧱 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Updated Evaluation with Threshold = 0.08\n",
    "\n",
    "After analyzing the threshold-performance tradeoff, we tested the Random Forest model using a **custom threshold of 0.08**, rather than the default 0.50.\n",
    "\n",
    "### 📊 Classification Report:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 🧠 Key Observations:\n",
    "- **Precision-Recall Trade-off Balanced**: \n",
    "  - Recall for defaulters (class 1) = 70% ➝ majority of defaulters caught.\n",
    "  - Precision for defaulters = 50% ➝ half of the predicted defaulters are correct.\n",
    "- **True Positives = 9478** and **True Negatives = 5672**.\n",
    "- Accuracy = 52% ➝ still modest, but better than threshold = 0.00.\n",
    "\n",
    "### ✅ Why 0.08 is Better than 0.00:\n",
    "| Metric        | Threshold = 0.00 | Threshold = 0.08 |\n",
    "|---------------|------------------|------------------|\n",
    "| Precision (1) | 0.47             | 0.50             |\n",
    "| Recall (1)    | 1.00             | 0.70             |\n",
    "| F1 Score (1)  | 0.64             | 0.58             |\n",
    "| Accuracy      | 0.47             | 0.52             |\n",
    "\n",
    "While recall dropped slightly, we gained a **significant boost in precision**, making this a **much more realistic** and **deployable** model.\n",
    "\n",
    "### 📌 Final Thought:\n",
    "This threshold strikes a better **balance between catching defaulters and avoiding false alarms**. You may further fine-tune around 0.07–0.10 for optimal business value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Set Best Threshold (optional: test slightly higher ones if needed) ---\n",
    "best_threshold = 0.07\n",
    "\n",
    "# --- 2. Predict using Probabilities ---\n",
    "y_probs = rf_balanced.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "y_pred_final = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# --- 3. Evaluation ---\n",
    "print(\"📌 Updated Evaluation using Best Threshold\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "print(\"🧱 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Set Best Threshold (optional: test slightly higher ones if needed) ---\n",
    "best_threshold = 0.06\n",
    "\n",
    "# --- 2. Predict using Probabilities ---\n",
    "y_probs = rf_balanced.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "y_pred_final = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# --- 3. Evaluation ---\n",
    "print(\"📌 Updated Evaluation using Best Threshold\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "print(\"🧱 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Set Best Threshold (optional: test slightly higher ones if needed) ---\n",
    "best_threshold = 0.09\n",
    "\n",
    "# --- 2. Predict using Probabilities ---\n",
    "y_probs = rf_balanced.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "y_pred_final = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# --- 3. Evaluation ---\n",
    "print(\"📌 Updated Evaluation using Best Threshold\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "print(\"🧱 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Set Best Threshold (optional: test slightly higher ones if needed) ---\n",
    "best_threshold = 0.10\n",
    "\n",
    "# --- 2. Predict using Probabilities ---\n",
    "y_probs = rf_balanced.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "y_pred_final = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# --- 3. Evaluation ---\n",
    "print(\"📌 Updated Evaluation using Best Threshold\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "print(\"🧱 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Set Best Threshold (optional: test slightly higher ones if needed) ---\n",
    "best_threshold = 0.11\n",
    "\n",
    "# --- 2. Predict using Probabilities ---\n",
    "y_probs = rf_balanced.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "y_pred_final = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# --- 3. Evaluation ---\n",
    "print(\"📌 Updated Evaluation using Best Threshold\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "print(\"🧱 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Set Best Threshold (optional: test slightly higher ones if needed) ---\n",
    "best_threshold = 0.15\n",
    "\n",
    "# --- 2. Predict using Probabilities ---\n",
    "y_probs = rf_balanced.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "y_pred_final = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# --- 3. Evaluation ---\n",
    "print(\"📌 Updated Evaluation using Best Threshold\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "print(\"🧱 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Set Best Threshold (optional: test slightly higher ones if needed) ---\n",
    "best_threshold = np.arange(0.05, 0.15, 0.005)\n",
    "\n",
    "confusion_matrix_data = []\n",
    "\n",
    "# --- 2. Predict using Probabilities ---\n",
    "for i in best_threshold:\n",
    "    y_probs = rf_balanced.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "    y_pred_final = (y_probs >= i).astype(int)\n",
    "    conf_norm = confusion_matrix(y_test, y_pred_final, normalize='true')\n",
    "    # Flatten the 2x2 matrix and store with threshold\n",
    "    row = [i] + conf_norm.flatten().tolist()\n",
    "    confusion_matrix_data.append(row)\n",
    "#y_pred_final = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# Create DataFrame\n",
    "confusion_df = pd.DataFrame(confusion_matrix_data, columns=[\n",
    "    \"Threshold\", \n",
    "    \"True Negative Rate (TN)\", \"False Positive Rate (FP)\", \n",
    "    \"False Negative Rate (FN)\", \"True Positive Rate (TP)\"\n",
    "])\n",
    "\n",
    "# Display the DataFrame\n",
    "confusion_df.set_index(\"Threshold\", inplace=True)\n",
    "display(confusion_df)\n",
    "\n",
    "# --- 3. Evaluation ---\n",
    "#print(\"📌 Updated Evaluation using Best Threshold\")\n",
    "#print(classification_report(y_test, y_pred_final))\n",
    "#print(\"🧱 Confusion Matrix:\")\n",
    "#print(confusion_matrix(y_test, y_pred_final, normalize='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Model Comparison Summary: SVC + SMOTE vs. Random Forest (Weighted + Thresholded)\n",
    "\n",
    "### ✅ SVC + SMOTE (No Tuning, No Thresholding)\n",
    "\n",
    "| Metric                     | Value     |\n",
    "|---------------------------|-----------|\n",
    "| **Accuracy**              | 0.6173    |\n",
    "| **Precision**             | 0.6134    |\n",
    "| **Recall (TPR)**          | 0.5063    |\n",
    "| **F1 Score**              | 0.5547    |\n",
    "| **ROC AUC Score**         | 0.6822    |\n",
    "| **True Negative Rate (TNR)** | 0.7165    |\n",
    "| **False Positive Rate (FPR)** | 0.2835    |\n",
    "\n",
    "📌 *Balanced performance across both classes, especially better recall on defaulters.*\n",
    "\n",
    "---\n",
    "\n",
    "### 🟨 Random Forest + Class Weight + Threshold = 0.075\n",
    "\n",
    "| Metric                     | Value     |\n",
    "|---------------------------|-----------|\n",
    "| **Accuracy**              | 0.52      |\n",
    "| **Precision**             | 0.50      |\n",
    "| **Recall (TPR)**          | 0.6962    |\n",
    "| **F1 Score**              | 0.58      |\n",
    "| **ROC AUC Score**         | Lower than 0.6822 |\n",
    "| **True Negative Rate (TNR)** | 0.3707    |\n",
    "| **False Positive Rate (FPR)** | 0.6293    |\n",
    "\n",
    "📌 *Higher recall on defaulters but at the cost of many false positives.*\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Final Conclusion\n",
    "\n",
    "- ✅ **SVC + SMOTE** provides the most **balanced** and **robust** performance among all strategies tested.\n",
    "- 🎯 Even without hyperparameter tuning, this model achieves the **highest ROC AUC Score** and **better generalization**.\n",
    "- 🧪 Techniques like **class weighting and threshold tuning** were explored but did **not outperform the baseline best**.\n",
    "- 🧾 *This strengthens confidence in model choice and serves as an excellent checkpoint in the project pipeline.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ 1. Model Interpretation (Optional but Valuable)\n",
    "#### Use SHAP or LIME for interpreting why the SVC model is making certain predictions.\n",
    "#### This adds value to explainability and trust in your model, especially for real-world applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize the CSV for SVC + SMOTE\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": original_test[\"ID\"],\n",
    "    \"Loan Status\": svc.predict(X_test)\n",
    "})\n",
    "submission.to_csv(\"final_submission_svc_smote.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Step 1: Submission File Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Predict on Test Set ---\n",
    "X_final_test = df_test_encoded.drop(columns=[\"Loan Status\"])  # Ensure 'Loan Status' is not in test\n",
    "y_pred_final = svc.predict(X_final_test)\n",
    "\n",
    "# --- 2. Build Submission File ---\n",
    "submission_df = pd.DataFrame({\n",
    "    \"ID\": original_test[\"ID\"],  # Assuming you restored 'ID' earlier from original test.csv\n",
    "    \"Loan Status\": y_pred_final\n",
    "})\n",
    "\n",
    "# --- 3. Save to CSV ---\n",
    "submission_df.to_csv(\"final_submission_svc_smote.csv\", index=False)\n",
    "print(\"✅ Final submission file 'final_submission_svc_smote.csv' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📁 Step 2: Project Documentation Structure (Markdown Format)\n",
    "\n",
    "### 🧠 1. Project Overview\n",
    "#### 🧠 Project Overview\n",
    "\n",
    "The goal of this project is to build a machine learning model that predicts **loan default risk** using historical data. This involves complete preprocessing, feature engineering, resampling, model selection, evaluation, and performance tuning.\n",
    "\n",
    "Data Source: Kaggle Bank Loan Defaulter Challenge  \n",
    "Objective: Predict the `Loan Status` of each application in the test set.\n",
    "\n",
    "\n",
    "### 📊 2. Exploratory Data Analysis (EDA)\n",
    "## 📊 Exploratory Data Analysis (EDA)\n",
    "\n",
    "We analyzed numerical and categorical columns to assess variance, cardinality, and dominant categories. Based on the insights, we dropped uninformative columns such as:\n",
    "- `Application Type`: Dominant category ratio > 99%\n",
    "- `Loan Title`: High cardinality with sparse distribution\n",
    "\n",
    "We also visualized missing values and distributions.\n",
    "\n",
    "### 🧼 3. Preprocessing & Feature Engineering\n",
    "## 🧼 Preprocessing & Feature Engineering\n",
    "\n",
    "- Mapped ordinal columns (like `Grade`) manually.\n",
    "- Applied:\n",
    "  - One-Hot Encoding to: `Initial List Status`, `Employment Duration`, `Verification Status`\n",
    "  - Label Encoding to: `Sub Grade`, `Batch Enrolled`\n",
    "  - Frequency Encoding to: `Loan Title`\n",
    "- Combined `train` and `test` datasets for uniform encoding, then split them back.\n",
    "\n",
    "### ⚖️ 4. Resampling Strategy\n",
    "## ⚖️ Resampling Strategy\n",
    "\n",
    "To handle class imbalance in `Loan Status`, we used:\n",
    "- **SMOTE** (oversampling) — better recall and balanced results\n",
    "- **NearMiss** (undersampling) — less effective on our data\n",
    "\n",
    "Final model selection was based on resampling performance.\n",
    "\n",
    "### 🤖 5. Model Training & Evaluation\n",
    "## 🤖 Model Training & Evaluation\n",
    "\n",
    "We evaluated multiple models before and after resampling:\n",
    "\n",
    "| Model            | Resampling | F1 Score | ROC AUC | Accuracy |\n",
    "|------------------|------------|----------|---------|----------|\n",
    "| LogisticRegression | SMOTE    | 0.516    | 0.584   | 0.556    |\n",
    "| DecisionTree       | SMOTE    | 0.278    | 0.502   | 0.520    |\n",
    "| RandomForest       | SMOTE    | 0.051    | 0.517   | 0.533    |\n",
    "| SVC                | **SMOTE** | **0.555** | **0.682** | **0.617** |\n",
    "| XGBoost            | NearMiss | 0.475    | 0.280   | 0.366    |\n",
    "\n",
    "✅ Best Model: **SVC + SMOTE**\n",
    "\n",
    "### 🎯 6. Error Analysis\n",
    "## 🎯 Error Analysis\n",
    "\n",
    "- False Negatives were significant in the original model.\n",
    "- Adjusting the classification threshold improved recall and F1-score.\n",
    "- Chose threshold = `0.075` for balanced performance.\n",
    "\n",
    "Normalized Confusion Matrix:\n",
    "| TN Rate | FP Rate | FN Rate | TP Rate |\n",
    "|---------|---------|---------|---------|\n",
    "| 0.370   | 0.630   | 0.304   | 0.696   |\n",
    "\n",
    "\n",
    "### 📝 7. Final Model & Submission\n",
    "## 📝 Final Model & Submission\n",
    "\n",
    "- Final Model: SVC trained with SMOTE\n",
    "- Final Threshold: `0.075`\n",
    "- Submission File: `final_submission_svc_smote.csv`\n",
    "\n",
    "\n",
    "### 🚀 8. Future Improvements\n",
    "## 🚀 Future Improvements\n",
    "\n",
    "- Try feature selection techniques like Recursive Feature Elimination (RFE)\n",
    "- Ensemble of top 3 models\n",
    "- Deep learning architectures\n",
    "- Bayesian optimization for hyperparameter tuning\n",
    "\n",
    "\n",
    "### ✅ 9. Interview Prep Insights\n",
    "## ✅ Interview Prep Insights\n",
    "\n",
    "- Explained EDA, preprocessing, encoding logic, model selection criteria\n",
    "- Covered metrics deeply: Accuracy, Precision, Recall, F1, ROC AUC\n",
    "- Understood threshold tuning, error analysis, and pipeline structuring\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚙️ Step 3: Save & Load the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the final best model (SVC + SMOTE pipeline)\n",
    "joblib.dump(svc, \"svc_smote_model.pkl\")\n",
    "\n",
    "# If you used a scaler like StandardScaler or MinMaxScaler, also save it\n",
    "# joblib.dump(scaler, \"scaler.pkl\")  # optional\n",
    "print(\"✅ Model saved as 'svc_smote_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 3.2 Load the Model Later for Inference\n",
    "# Load the model later\n",
    "loaded_model = joblib.load(\"svc_smote_model.pkl\")\n",
    "\n",
    "# Predict using loaded model\n",
    "y_pred_loaded = loaded_model.predict(X_kaggle_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📁 3.3 Save Preprocessed Test Data (Optional)\n",
    "#### For reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_encoded.to_csv(\"encoded_test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧪 3.4 Verify Predictions Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (y_pred_loaded == svc.predict(X_kaggle_test)).all()\n",
    "print(\"✅ Loaded model works identically to original!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Why Save and Load the Model?\n",
    "\n",
    "When working on real-world machine learning projects, it’s essential to **preserve your trained model** so that it can be reused or deployed without retraining every time. This process is known as **model serialization**.\n",
    "\n",
    "### ✅ Benefits of Saving Your Model\n",
    "- **Reusability**: You don’t need to retrain the model each time you want to use it, saving time and compute.\n",
    "- **Deployment**: You can deploy the model in a web service (e.g., Flask, FastAPI, or Streamlit) or embed it into an app or pipeline.\n",
    "- **Reproducibility**: Saving both the model and any pre-processing steps ensures consistent results in future predictions.\n",
    "- **Portability**: You can easily share your model with others or move it between environments (local, cloud, server).\n",
    "\n",
    "---\n",
    "\n",
    "### 📦 What to Save?\n",
    "- **Trained Model**: e.g., `RandomForestClassifier`, `SVC`, etc.\n",
    "- **Preprocessing Steps**: Encoders, scalers (like `StandardScaler`, `MinMaxScaler`, `LabelEncoder`), and feature transformers.\n",
    "- **Pipelines**: Combining multiple steps (e.g., SMOTE + SVC) into a single object that encapsulates the full ML process.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 What You Gain\n",
    "- 🕒 Save hours of training time  \n",
    "- 🚀 Easy integration into APIs or UI apps  \n",
    "- 🔄 Simplified version control and model updates  \n",
    "- 🧾 Helps you create reproducible notebooks and submissions\n",
    "\n",
    "---\n",
    "\n",
    "### 🛠 Tools Commonly Used\n",
    "| Library   | Description                                |\n",
    "|-----------|--------------------------------------------|\n",
    "| `joblib`  | Fast and efficient way to serialize models |\n",
    "| `pickle`  | Python's built-in serializer (less efficient for large NumPy arrays) |\n",
    "| `ONNX`    | Open Neural Network Exchange (for inter-framework compatibility) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the feauture names.\n",
    "feature_names = df_train_encoded.drop(columns=[\"Loan Status\"]).columns.tolist()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dash App creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Feature: Guided User Input with Validation Hints\n",
    "\n",
    "To improve user experience and reduce input errors in the loan default prediction app, we implemented the following enhancements:\n",
    "\n",
    "### 1. Data Type Detection\n",
    "- For each input feature, we determine its **expected data type** from the training dataset.\n",
    "- This allows us to set suitable **placeholder values** and define meaningful **tooltip hints**.\n",
    "\n",
    "### 2. Placeholder Hints\n",
    "- Each input field displays `\"Enter Value (e.g., 15000)\"` as a placeholder.\n",
    "- The example is dynamically generated based on the actual data type or common value range.\n",
    "\n",
    "### 3. Mouse Hover Tooltip\n",
    "- When a user hovers over a field, a tooltip appears showing a **detailed description or example** for the input.\n",
    "- This helps prevent format errors (e.g., entering strings where integers are expected).\n",
    "\n",
    "### 4. Optional Future Enhancements\n",
    "- Input validation that restricts typing to allowed formats.\n",
    "- Auto-suggestion or drop-downs for categorical fields.\n",
    "\n",
    "This combination ensures a cleaner UI and smarter form input handling for model deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎛️ Input UI Design for Dash App\n",
    "\n",
    "## 🎯 Objective\n",
    "\n",
    "To enhance user experience and ensure data integrity, we aim to create a user-friendly input form where each input field:\n",
    "- Accepts only valid values based on the feature's data type.\n",
    "- Provides a default prompt like \"Enter Value\".\n",
    "- Shows an example tooltip on hover for guidance.\n",
    "\n",
    "## 🧠 How It Works\n",
    "\n",
    "1. **7x5 Grid Layout**:\n",
    "   - Inputs are arranged in a grid layout of 7 rows and 5 columns.\n",
    "   - This ensures compactness and better use of screen space.\n",
    "\n",
    "2. **Dynamic Tooltips**:\n",
    "   - Each input field has a tooltip that displays an example value extracted from the training dataset.\n",
    "   - Hovering over the input field will show guidance like:  \n",
    "     _\"Example: 12000\"_ or _\"Example: Verified\"_.\n",
    "\n",
    "3. **Input Type Enforcement**:\n",
    "   - Numerical fields use `type='number'` to prevent invalid entries.\n",
    "   - Categorical fields use dropdowns or text with validation logic in the backend.\n",
    "\n",
    "## ✅ Benefits\n",
    "\n",
    "- Prevents user input errors at the UI level.\n",
    "- Reduces backend validation complexity.\n",
    "- Ensures better form completion rate and usability.\n",
    "\n",
    "## 🔍 Example Input Field (in Dash)\n",
    "```python\n",
    "dcc.Input(\n",
    "    id='loan_amount',\n",
    "    type='number',\n",
    "    placeholder='Enter Loan Amount',\n",
    "    debounce=True,\n",
    "    title='Example: 12000'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧠 Why the Dash App Fails Without Preprocessing?\n",
    "\n",
    "When we train a machine learning model using **scikit-learn**, we typically convert all categorical (text-based) features into **numerical representations** — because models like `SVC`, `RandomForest`, or `XGBoost` **cannot operate on raw string data**.\n",
    "\n",
    "This process is called **feature engineering**, which often includes:\n",
    "\n",
    "- **One-hot encoding** (e.g., `Home Ownership = RENT` → column `Home Ownership_RENT = 1`)\n",
    "- **Label encoding**\n",
    "- **Scaling** (e.g., MinMaxScaler or StandardScaler)\n",
    "- **Handling missing values**\n",
    "- **Date feature extraction** (e.g., month, year)\n",
    "\n",
    "During training, this transformation was applied **before the model saw the data**, and the model only learned from the transformed features — which are **all numeric**.\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ Problem in the Current Dash App\n",
    "\n",
    "Right now, the app takes user input as raw values like:\n",
    "```python\n",
    "\"Term\" = \"Short Term\"  # string\n",
    "\"Home Ownership\" = \"RENT\"  # string\n",
    "```\n",
    "\n",
    "But then it sends these **raw strings** to the trained model:\n",
    "```python\n",
    "model.predict(input_data)\n",
    "```\n",
    "\n",
    "The model expects preprocessed numeric input like:\n",
    "```python\n",
    "\"Term_Short Term\" = 1\n",
    "\"Home Ownership_RENT\" = 1\n",
    "\"Home Ownership_OWN\" = 0\n",
    "```\n",
    "\n",
    "Hence, you're getting errors like:\n",
    "```plaintext\n",
    "could not convert string to float: 'Short Term'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Correct Approach for Deployment\n",
    "\n",
    "1. **Recreate your exact preprocessing pipeline** used during training.\n",
    "2. **Save this pipeline** as a `Pipeline` object that combines both preprocessing and the model.\n",
    "3. In the Dash app:\n",
    "   - Accept raw user input\n",
    "   - Pass it through the same pipeline\n",
    "   - Then send it to `.predict()` or `.predict_proba()`\n",
    "\n",
    "This ensures your input format **matches** the model’s training data structure.\n",
    "\n",
    "---\n",
    "\n",
    "### 🛠️ What Should You Do Next?\n",
    "\n",
    "You need to **retrain or refit** your model inside a `Pipeline`, like this:\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Step 1: Define preprocessing\n",
    "categorical_cols = [\"Term\", \"Home Ownership\", ...]\n",
    "numerical_cols = [\"Loan Amount\", \"Interest Rate\", ...]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "    (\"num\", \"passthrough\", numerical_cols)\n",
    "])\n",
    "\n",
    "# Step 2: Combine preprocessing + model\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", SVC(probability=True))\n",
    "])\n",
    "\n",
    "# Step 3: Fit pipeline\n",
    "pipeline.fit(X_raw, y)  # X_raw = original unprocessed DataFrame\n",
    "\n",
    "# Step 4: Save pipeline\n",
    "import joblib\n",
    "joblib.dump(pipeline, \"svc_pipeline_model.pkl\")\n",
    "```\n",
    "\n",
    "Then in your Dash app, simply load and use:\n",
    "\n",
    "```python\n",
    "model = joblib.load(\"svc_pipeline_model.pkl\")\n",
    "model.predict(user_input_df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "This guarantees your deployed app is using the **same pipeline logic** as used during training, making it robust and production-ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔁 Why Retrain Inside a Pipeline?\n",
    "When you trained your model earlier, you:\n",
    "\n",
    "    - Cleaned and encoded your DataFrame using pandas (like one-hot encoding)\n",
    "    - Dropped or transformed columns manually\n",
    "    - Fed the final numerical DataFrame into the model\n",
    "    - That was great for offline evaluation, but now in your Dash app:\n",
    "\n",
    "The user is entering raw values (like \"RENT\" or \"Short Term\")\n",
    "The model expects preprocessed numbers\n",
    "So you need to bundle the preprocessing + model together into a Pipeline so it handles everything seamlessly during prediction\n",
    "\n",
    "## 🧠 Next Step\n",
    "Now that you're ready, let’s:\n",
    "\n",
    "    - Rebuild your preprocessing logic using ```ColumnTransformer```\n",
    "    - Combine it with ```SVC(probability=True)``` inside a ```Pipeline```\n",
    "    - Fit the pipeline on raw training data (train.csv)\n",
    "    - Save the pipeline as ```svc_pipeline_model.pkl```\n",
    "\n",
    "## Use it in Dash 🎯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "class BankLoanPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.grade_order = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7}\n",
    "        self.label_cols = [\"Sub Grade\", \"Batch Enrolled\"]\n",
    "        self.label_encoders = {}\n",
    "        self.freq_map = None\n",
    "        self.one_hot_cols = [\"Initial List Status\", \"Employment Duration\", \"Verification Status\"]\n",
    "        self.one_hot_columns_fitted = None  # to align test data with train\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Fit Label Encoders\n",
    "        for col in self.label_cols:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[col].astype(str))\n",
    "            self.label_encoders[col] = le\n",
    "\n",
    "        # Fit Frequency Encoding\n",
    "        self.freq_map = X[\"Loan Title\"].value_counts().to_dict()\n",
    "\n",
    "        # Fit One-Hot Columns\n",
    "        dummies = pd.get_dummies(X[self.one_hot_cols], drop_first=True)\n",
    "        self.one_hot_columns_fitted = dummies.columns.tolist()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Grade Ordinal Mapping\n",
    "        X[\"Grade\"] = X[\"Grade\"].map(self.grade_order)\n",
    "\n",
    "        # Label Encoding\n",
    "        for col in self.label_cols:\n",
    "            X[col] = self.label_encoders[col].transform(X[col].astype(str))\n",
    "\n",
    "        # Frequency Encoding\n",
    "        X[\"Loan Title\"] = X[\"Loan Title\"].map(self.freq_map).fillna(0)\n",
    "\n",
    "        # One-Hot Encoding (align columns)\n",
    "        dummies = pd.get_dummies(X[self.one_hot_cols], drop_first=True)\n",
    "        for col in self.one_hot_columns_fitted:\n",
    "            if col not in dummies:\n",
    "                dummies[col] = 0\n",
    "        dummies = dummies[self.one_hot_columns_fitted]\n",
    "        X = X.drop(columns=self.one_hot_cols)\n",
    "        X = pd.concat([X, dummies], axis=1)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Imports ---\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Custom transformer from previous step\n",
    "#from bank_preprocessor import BankLoanPreprocessor  # or copy-paste the class if in same notebook\n",
    "\n",
    "# --- 2. Prepare Data ---\n",
    "# 1. Split back into raw training and test data\n",
    "df_train_raw = df_combined.loc[\"train\"].copy()\n",
    "df_test_raw = df_combined.loc[\"test\"].copy()\n",
    "\n",
    "# 2. Define features and target\n",
    "X_raw = df_train_raw.drop(columns=[\"Loan Status\"])\n",
    "y_raw = df_train_raw[\"Loan Status\"]\n",
    "\n",
    "X_kaggle_test = df_test_raw.drop(columns=[\"Loan Status\"])\n",
    "y_kaggle_test = df_test_raw[\"Loan Status\"]\n",
    "\n",
    "\n",
    "# Split for evaluation purposes\n",
    "#X_train_raw, X_val_raw, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y_raw)\n",
    "\n",
    "# --- 3. Define Pipeline ---\n",
    "pipeline = ImbPipeline([\n",
    "    (\"preprocessor\", BankLoanPreprocessor()),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# --- 4. Fit the Pipeline ---\n",
    "pipeline.fit(X_raw, y_raw)\n",
    "\n",
    "# --- 5. Evaluate ---\n",
    "y_pred = pipeline.predict(X_kaggle_test)\n",
    "print(\"📊 Classification Report:\\n\", classification_report(y_kaggle_test, y_pred))\n",
    "print(\"🧱 Confusion Matrix:\\n\", confusion_matrix(y_kaggle_test, y_pred))\n",
    "\n",
    "# --- 6. Save the model ---\n",
    "joblib.dump(pipeline, \"rf_pipeline_model.pkl\")\n",
    "print(\"✅ Model saved as 'rf_pipeline_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Kaggle test set (raw)\n",
    "y_pred_kaggle = pipeline.predict(df_test)\n",
    "print(classification_report(df_target[\"Loan Status\"], y_pred_kaggle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧠 Why the Dash App Fails Without Preprocessing?\n",
    "\n",
    "When we train a machine learning model using **scikit-learn**, we typically convert all categorical (text-based) features into **numerical representations** — because models like `SVC`, `RandomForest`, or `XGBoost` **cannot operate on raw string data**.\n",
    "\n",
    "This process is called **feature engineering**, which often includes:\n",
    "\n",
    "- **One-hot encoding** (e.g., `Home Ownership = RENT` → column `Home Ownership_RENT = 1`)\n",
    "- **Label encoding**\n",
    "- **Scaling** (e.g., MinMaxScaler or StandardScaler)\n",
    "- **Handling missing values**\n",
    "- **Date feature extraction** (e.g., month, year)\n",
    "\n",
    "During training, this transformation was applied **after merging** `df_train` and `df_test` into `df_combined`. This ensured **consistent encoding across all values**, even if a value appeared only in the test set (e.g., `'n'` or `'BAT2522922'` in `Batch Enrolled`).\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ Problem in the Current Pipeline\n",
    "\n",
    "Now, when trying to train or deploy a new model with only `df_train` or `df_test` separately, these inconsistencies **resurface** because unseen labels are not accounted for:\n",
    "\n",
    "```plaintext\n",
    "ValueError: could not convert string to float: 'n'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Solution: Reuse Consistent Transformation\n",
    "\n",
    "To ensure consistent encoding, we need to:\n",
    "\n",
    "1. Combine the original cleaned `df_train` and `df_test` again into `df_combined`:\n",
    "```python\n",
    "combined = pd.concat([df_train, df_test], axis=0, keys=[\"train\", \"test\"])\n",
    "```\n",
    "\n",
    "2. Apply encoding to the entire `df_combined`:\n",
    "```python\n",
    "# Grade ordinal encoding\n",
    "combined['Grade'] = combined['Grade'].map(grade_order)\n",
    "\n",
    "# Label encoding\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    combined[col] = le.fit_transform(combined[col].astype(str))\n",
    "\n",
    "# Frequency encoding for Loan Title\n",
    "combined['Loan Title'] = combined['Loan Title'].map(freq_map).fillna(0)\n",
    "\n",
    "# One-hot encoding\n",
    "combined = pd.get_dummies(combined, columns=one_hot_cols, drop_first=True)\n",
    "```\n",
    "\n",
    "3. Split them back:\n",
    "```python\n",
    "X_train_final = combined.loc['train'].drop(columns=['Loan Status'])\n",
    "y_train_final = combined.loc['train']['Loan Status']\n",
    "X_test_final = combined.loc['test'].drop(columns=['Loan Status'])\n",
    "y_test_final = combined.loc['test']['Loan Status']\n",
    "```\n",
    "\n",
    "4. Use these for fitting your final pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧱 Outcome\n",
    "\n",
    "By encoding consistently across both training and test datasets upfront, you avoid mismatches and ensure your model generalizes well at inference time — especially when deployed or reused in apps.\n",
    "\n",
    "Let me know to implement this in code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Combine cleaned train and test sets\n",
    "combined = pd.concat([df_train, df_test], axis=0, keys=[\"train\", \"test\"])\n",
    "\n",
    "# Grade ordinal encoding\n",
    "grade_order = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7}\n",
    "combined['Grade'] = combined['Grade'].map(grade_order)\n",
    "\n",
    "# Label encoding\n",
    "label_cols = [\"Sub Grade\", \"Batch Enrolled\"]\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    combined[col] = le.fit_transform(combined[col].astype(str))\n",
    "\n",
    "# Frequency encoding for Loan Title\n",
    "freq_map = combined[\"Loan Title\"].value_counts().to_dict()\n",
    "combined[\"Loan Title\"] = combined[\"Loan Title\"].map(freq_map).fillna(0)\n",
    "\n",
    "# One-hot encoding\n",
    "one_hot_cols = [\"Initial List Status\", \"Employment Duration\", \"Verification Status\"]\n",
    "combined = pd.get_dummies(combined, columns=one_hot_cols, drop_first=True)\n",
    "\n",
    "# Final train-test split\n",
    "X_train_final = combined.loc['train'].drop(columns=['Loan Status'])\n",
    "y_train_final = combined.loc['train']['Loan Status']\n",
    "X_test_final = combined.loc['test'].drop(columns=['Loan Status'])\n",
    "y_test_final = combined.loc['test']['Loan Status']\n",
    "\n",
    "# Define pipeline\n",
    "pipeline = ImbPipeline([\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Train pipeline\n",
    "pipeline.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = pipeline.predict(X_test_final)\n",
    "print(\"📊 Classification Report:\\n\", classification_report(y_test_final, y_pred))\n",
    "print(\"🧱 Confusion Matrix:\\n\", confusion_matrix(y_test_final, y_pred))\n",
    "\n",
    "# Save model\n",
    "import joblib\n",
    "joblib.dump(pipeline, \"final_rf_model.pkl\")\n",
    "print(\"✅ Model saved as 'final_rf_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Combine cleaned train and test sets\n",
    "combined = pd.concat([df_train, df_test], axis=0, keys=[\"train\", \"test\"])\n",
    "\n",
    "# Grade ordinal encoding\n",
    "grade_order = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7}\n",
    "combined['Grade'] = combined['Grade'].map(grade_order)\n",
    "\n",
    "# Label encoding\n",
    "label_cols = [\"Sub Grade\", \"Batch Enrolled\"]\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    combined[col] = le.fit_transform(combined[col].astype(str))\n",
    "\n",
    "# Frequency encoding for Loan Title\n",
    "freq_map = combined[\"Loan Title\"].value_counts().to_dict()\n",
    "combined[\"Loan Title\"] = combined[\"Loan Title\"].map(freq_map).fillna(0)\n",
    "\n",
    "# One-hot encoding\n",
    "one_hot_cols = [\"Initial List Status\", \"Employment Duration\", \"Verification Status\"]\n",
    "combined = pd.get_dummies(combined, columns=one_hot_cols, drop_first=True)\n",
    "\n",
    "# Final train-test split\n",
    "X_train_final = combined.loc['train'].drop(columns=['Loan Status'])\n",
    "y_train_final = combined.loc['train']['Loan Status']\n",
    "X_test_final = combined.loc['test'].drop(columns=['Loan Status'], errors='ignore')\n",
    "\n",
    "# Define pipeline\n",
    "pipeline = ImbPipeline([\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Train pipeline\n",
    "pipeline.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(pipeline, \"final_rf_model.pkl\")\n",
    "print(\"✅ Model saved as 'final_rf_model.pkl'\")\n",
    "\n",
    "# Create final submission\n",
    "preds = pipeline.predict(X_test_final)\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": original_test[\"ID\"],\n",
    "    \"Loan Status\": preds\n",
    "})\n",
    "submission.to_csv(\"final_submission.csv\", index=False)\n",
    "print(\"📁 'final_submission.csv' created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
